### 一. Algorithm

做了 [153. Find Minimum in Rotated Sorted Array](https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/)。给出一个升序无重复元素的数组，该数组可能围绕某个节点进行了一次旋转，查找数组中的最小值。

旋转后的数组示例如下：

```
[0,1,2,4,5,6,7] > [4,5,6,7,0,1,2]

```

是一道考察二分查找的题目，首先针对数组是否旋转有三种情况：

```
- 数组只有一个元素       ->  返回该元素
- 数组没有旋转，完全正序  ->  返回第一个元素
- 数组有旋转            -> 基于二分查找返回最小元素
 
```

针对旋转后的数组有一个特点就是：

> [4,5,6,7,0,1,2]
> 最小值左侧为升序，右侧为降序，并且升序部分中的值大于降序部分的值

那么二分查找的规则为：


- 如果 nums[min] 小于 mid 值，此时 mid 位于升序部分，最小值在 mid 右侧
- 如果 nums[min] 大于 mid 值，此时 mid 位于降序部分，最小值在 mid 左侧

通过这样最终获取到 min 索引，此时 min 要么是最小值，要么是最大值，再做一次判断即可获取最小值。

综上思路，实现代码如下：

```Java
class Solution {
    public int findMin(int[] nums) {
        int len = nums.length;
        
        // 1. 长度为 0
        if (len == 1) {
            return nums[0];
        }

        int min = 0;
        int max = len - 1;
		  
		  // 2. 完全逆序
        if (nums[min] < nums[max]) {
            return nums[min];
        }
		
		
		 // 3. 基于二分查找获取最小元素的索引
        int mid = (min + max) / 2;

        while (min <= max) {
            if (nums[min] <  nums[mid]) {
                min = mid;
                mid = (min + max) / 2;
            }else if (nums[min] > nums[mid]){
                max = mid;
                mid = (min + max) / 2;
            }else {
                min = mid + 1;
                mid = (min + max) / 2;

            }
        }
		
		 // 4. 如果 min 后还有一个值，比较去最小值
        if (min < len -1) {
            if (nums[min] > nums[min + 1]) {
                return nums[min + 1];
            }
        }
        return nums[min];

    }
 }
```

在没有旋转的情况下时间复杂度为 O(1)，通过二分查找情况下复杂度为 O(logN)。


### 二. Review

本地 Review 读了皓叔在专栏中推荐的一篇文章:[Should You Put Several Event Types in the Same Kafka Topic?](https://www.confluent.io/blog/put-several-event-types-kafka-topic/)。

文章介绍了在使用 Kafka 时如何决定 topic 的数量，是是将所有的 event 发送到同一个 topic 还是拆分为很多个 topic。

下面是对文章提到的发送方式、问题和建议的简单总结：

#### 1. 几种发送方式与问题

##### 【1】使用 1 个 topic

一种简单粗暴的方式是使用同一个 topic 接收所有的消息，该种方式最大的问题就在于 consumer 必须要接收处理选择所有的消息，灵活性非常差。

##### 【2】拆分为较多的 topic

与第一种方式不同，另外一个极端就是尽可能细化 event 事件，然后发送给不同的 topic，但是 topic 过多会造成比较严重的性能问题，当 topic 过多时，内存消耗、消息延时、故障恢复时长都会有所增加。

另外一个就是顺序问题，Kafka 的消息是分区有序的，因此对于对有序性要求比较高的事件，比如用户创建、下单，下单事件的消息必须在用户创建后面，此时如果将两种消息发送到不同的 topic，那么会出现还没有看到用户创建就出现用户下单的问题。

#### 2. 何时拆分或者合并 topic?

- 1. 所有对事件顺序有要求的发送到同一 topic 中
- 2. 对于互相关联的 Entity 或者一般同时出现的事件，建议发送到同一个 topic 中，反之则可以发到不同的 topic 中
- 3. 某个事件关联到多个 Entity，必须转账，必须对两个账户进行操作，此时建议将该操作置为原子操作，放在一个事件消息中处理。
- 4. 从 consumer 的角度，如何多个 consumer 始终订某个分区中的几个 topic，此时可以考虑将几个 topic 进行合并
- 5. KTable 的 changelog topic 应该始终单独创建


### 三. Tips

分享一个 chrome 插件：[Octotree](https://github.com/ovity/octotree)，可以帮助我们在用 Chrome 看 Github 上的项目时展示其项目结构，示例如下：

没有安装插件时，查看 Github 项目时只能看到最上层的目录，

![](https://github.com/zouyingjie/arts/blob/master/image/arts_36_02.png)


安装插件之后，在 侧边就可以像在 IDE 中那样查看整个项目的结构，快速查看想要的文件了：

![](https://github.com/zouyingjie/arts/blob/master/image/arts_36_01.png)

### 四. Share

最近在看《Java 并发编程实战》书籍和极客时间的《Java 并发编程实战》专栏，看到关于死锁的部分。发现包括书籍在内的很多资料，都是简单讲解什么是死锁，然后就是给出一些可行的解决方式，比如

- 所有线程以固定的顺序获取锁
- 支持定时的锁

但是专栏中先提到了死锁发生需要满足的条件，然后在基于条件讲解决方案。对于死锁，仅满足下面四种情况时才会发生：

- 互斥
- 占有且等待
- 不可抢占
- 循环等待

那么只要破坏了上面任何一个就可以避免死锁了，基于这个在回头看书中提到的几种方式

- 以固定的顺序获得锁。这是破坏了第四种，避免了互相等待
- 定时锁。破坏了不可抢占，通过主动释放锁使其可以被抢占

另外基于第二种就是不让其等待了，可以通过一次性获取所有资源的方式来避免等待。

通过了解造成死锁的四个条件，然后针对引发问题条件在给出合适的解决方案。因为事先做到了知其所以然，后续的方案都做到了有的放矢，这样比单纯记住如何解决死锁要更加的令人印象深刻，遇到死锁问题时，排查思路也会更加的清晰。所以说学习知识，解决问题一定不要囿于表面，深入的理解原理和造成问题的原因，解决问题就不过是水到渠成的事情了。

另外一点就是对知识的高度总结、凝练。其实上面的四种情境在书中举得例子中是有所体现的，只不过没有像专栏中提炼的那么简洁而已，但是我们无法指望所有的知识都有人进行高度简洁的总结之后再去学习，因此在日常学习中一定要加强自己对知识的梳理、总结能力，穿过一个个的知识点，认识到背后的原理和联系，从而构建自己的知识体系，虽然这样做在一开始学习时会非常的慢，但随着知识点的不断积累和关联，学习的速度和深度会变得越来越快，形成一个正向的加速度，而不是单个知识点的记了忘，陷入狗熊掰棒子的囧境。