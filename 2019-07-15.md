### 一. Algorithm

做了两道 BST 相关的题目：[98. Validate Binary Search Tree](https://leetcode.com/problems/validate-binary-search-tree/) 和 [230. Kth Smallest Element in a BST](https://leetcode.com/problems/kth-smallest-element-in-a-bst/)。

Binary Search Tree(二叉查找树) 的特点是：

- 对于树中的每一个节点，其左子节点是值一定小于该节点，其右子节点的值一定大于该节点
- 按照中序遍历的方式遍历 BST，得到的是一个升序数组。

基于上面两个特点，对于第 [98. Validate Binary Search Tree](https://leetcode.com/problems/validate-binary-search-tree/) ，如果是 BST，那么中序遍历二叉树，遍历到的节点值一定大于已经。实现代码如下：

```Java
class Solution {

    private boolean isValid = true;
    // 避免输入的数是 Integer.MIN_VALUE 造成的问题，所以使用 long
    private long maxVal = Long.MIN_VALUE;

    public boolean isValidBST(TreeNode root) {
        if (root == null) {
            return true;
        }

        inOrder(root);
        return this.isValid;

    }

    private void inOrder(TreeNode node){
        if (node == null) {
            return;
        }

        inOrder(node.left);
        if (node.val <= maxVal) {
            this.isValid = false;
            return;
        }else {
            maxVal = node.val;
        }
        inOrder(node.right);
    }
}
```

对于 [230. Kth Smallest Element in a BST](https://leetcode.com/problems/kth-smallest-element-in-a-bst/) 依然是采用中序遍历，每遍历到 1 个节点则 index 加 1，index 为 K 时对应 Node 就是目标值，代码如下：

```Java
class Solution {
    private int result = 0;
    private int k = 0;
    private int index = 0;

    public int kthSmallest(TreeNode root, int k) {

        this.k = k;
        inOrder(root);
        return this.result;

    }

    public void inOrder(TreeNode node) {
        if (node == null) {
            return;
        }

        inOrder(node.left);
        index ++;
        if (index == k) {
            this.result = node.val;
            return;
        }
        inOrder(node.right);
    }
}
```

虽然是 Medium 难度，但是只要明白了 BST 的相关特性还是挺好做的。

### 二. Review

本周读了 [Best Practices for Efficient Log Management and Monitoring](https://sematext.com/blog/best-practices-for-efficient-log-management-and-monitoring/)。主要介绍了对云原生应用进行日志记录和监控的一些实践建议，简要总结如下：

#### 1. 使用托管服务

对于日志管理服务，可以有两种形式：第三方厂商提供的托管服务与自建服务。比如现在流行的日志收集工具 ELK 组件，既可以自己搭建，也可以使用云厂商的服务。作者这里更加推荐使用云厂商的托管服务，因为这可以节省我们大量的运维时间，从而可以将精力更多的放在如何制定我们的日志收集、管理、监控指标规范上，而不是花太多时间在服务维护管理上。

#### 2. 确定哪些信息需要监控，哪些不需要


对于日志服务，应该明确哪些数据是不需要收集的。因为理论上我们可以收集到所有我们想要收集的数据，但这些数据并不一定是有用的。数据过多不仅会增加数据分析的难度，也会增加数据存储的复杂性。

下面是一些必须收集的数据：

- 对生产环境的合规性和计量有关键影响的数据
- 可以帮助我们优化性能的相关数据，比如系统的各项指标，包括底层设施的基础指标，中间件层的各项指标，应用层的响应时间等指标
- 可以帮助解决用户体验问题的数据，比如各种错误日志等
- 安全相关的数据 

另外就是某些数据是可以明确不需要收集的，比如：

- 测试环境的相关数据，这些不是关键性数据，可以忽略。当然一般来说在测试环境也会搭建一套完整的日志管理设施用来对某些日志分析、管理做迭代和测试。不过这些在某些时候优先级可以靠后。
- 某些敏感数据比如信用卡号、身份证号、密码等数据尽量不要收集到日志中去， 除非保证日志是绝对安全不会被泄露的。

#### 3. 确认安全与保留策略

对于日志中的敏感数据，务必要在加密后才能写到日志中，应该禁止明文打日志的情况。关于敏感数据的日志安全策略可以参考这两篇文章：[GDPR: Top 5 Logging Best Practices](https://sematext.com/blog/gdpr-top-5-logging-best-practices/)、[GDPR and personal data in web server logs](https://sematext.com/docs/logagent/how-to-gdpr_web_logs/)。另外日志往日志管理服务的传输过程务必采用 HTTPS 协议来保证传输的安全性。

有的日志可能过几天就无效了，比如 Nginx 监控日志，没必要长期保存。而对于某些对业务等有重要影响的日志则需要制定长期保存策略。因此需要我们根据实际的日志类型和业务要求制定灵活的日志保留策略，

#### 4. 日志存储媒介

正常情况下日志的产生的速度基本是恒定的，但对于某些意外情况，比如系统发生故障导致错误日志量飙升。此时如果日志存储空间不够了，那么会最新的错误日志就无法被存储，从而导致我们没有有效的参考信息来修复故障，这是不允许被发生的事情。因此对于日志存储媒介要制定策略，当容量快满时要主动删除旧的数据，更进一步，我们的日志存储服务应该尽可能是可自动扩容伸缩的。

每个日志存储服务都要尽量有自己的安全策略。另外对于所有的攻击者而言，他们会避免留下痕迹或者尽量删除日志中的痕迹，因此为了避免该种情况的日志丢失，我们的日志收集应该是近实时的。

#### 5. 做好日志的 Review

实际业务和需求是不断变化的，我们的日志可能也要随之变化，因此做好日志的后续维护工作就显得非常重要，针对日志的 Review 主要集中在三个方面：可用性、操作和安全性。

具体要求有如下几条：

- 构建有意义的日志
- 日志数据结构化，比如使用 Json 等格式进行传输存储
- 经常性的检查审计日志
- 使用 checklist，文件给了一个校验清单可以帮助我们做好日志 Review，这里不做翻译了，直接引用下原文内容

> 
> Is the log message meaningful for users? 
> 
> Does the log message include context for troubleshooting?
> 
> Are the log message structured and include
>
> - timestamp,
>
> - severity/log level
> - message
> - additional troubleshooting information in separate fields
>    
> Are 3rd party logs parsed and structured (configure log shipper)?
> 
> Are log levels configurable?
> 
> Does the log message include personal data or security-related data?
> 
> Inspect audit logs and adjust log alert rules
> 
> Setup alerts on logs


#### 6. 关联数据后分析

> Connect the dots.

作者指出要注意关联相关的数据指标，做出综合的数据分析，而不是仅仅只分析某一类数据。可以通过 APM 等工具来做日志数据的聚合分析，然后整体反应系统的运行情况、事件，告警等，而不是将他们割裂开来一个个的去分析。


### 三. Tips

### 四. Share

读到一句对自己很有警醒的话：

> 好习惯一旦开始了就要尽量避免中场休息；手风顺的时候不要手软。
> 别低估惯性，别小看了你的惰性；运气、好习惯和技能一旦扔了，再捡起来就难了。

一旦决定要做某件事，不达目的誓不罢休，不要被阶段性的成就而迷惑，不要轻易满足进而导致懈怠。因为一旦放松了，可能就在难捡起来了，不要高估自己的自律能力，不要低估惰性，共勉。